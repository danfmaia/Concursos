# BACEN - Disciplina 6 - Ciência de Dados

# 6.1 - Inteligência Artificial (IA)

Prof. Vitor Kessler

- @vitor_kessler

## Agenda do Curso

1. Introdução à IA

2. Aprendizado de Máquina (AM) - Introdução

3. Classificação

   - Classificam exemplos em classes.

4. Redes Neurais Artificiais (RNA)

5. Regressão

   - Fazem previsões em um continuum.
   - É uma espécie de Classificação.

6. Clusterização (Agrupamento)

## 6.1.1 - Introdução à IA

- Campo _multidisciplinar_ da ciência da computação.

- Desenvolve _tecnologias autônomas_ p/ executar funções.

- Desenvolvimento de distemas e algoritmos capazes de realizar tarefas que normalmente exigem _inteligência humana_:

  - Criatividade
  - Auto aperfeiçoamento
  - Uso da linguagem
  - Visão computacional

- Os programas...

  - Aprendem.
  - Raciocionam.
  - Reconhecem padrões.
  - Inferem.
  - Tomam decisões.
  - Solucionam problemas.
  - Processam e analisam Big Data—grandes volumes de dados—de forma rápida e eficiente.

### Abordagens principais

- IA Simbólica:

  - Representação de conhecimento por meio de símbolos lógicos.
  - Estopim:
    > Sistemas especialistas baseados em lógica de primeira ordem construído com o Prolog.
  - Conhecimento programado diretamente por humanos.

- IA Conexionista:

  - Baseada em _redes neurais artificiais_.
  - Uso de _Machine Learning_.
  - Necessidade de _Big Data_.

### Tipos de IA

- Tipos segundo a Capacidade:

  - IA limitada (ou estreita).
  - IA geral.
  - Super IA.

- Tipos segundo a Funcionalidade:

  - Máquina reativa.
  - Memória limitada.
  - Teoria da mente.
  - Autoconsciente.

### Desafios da IA

- Processamento insuficiente de dados.
- Capacidade limitada de hardware.
- Interface Homem-Máquina.
- Custos altos.
- Considerações éticas.

### Áreas da IA

- Aprendizado de Máquina (AM) (Machine Learning) (ML)
  > Algoritmos que permitem que as máquinas aprendam com os dados e melhorem seu desempenho ao longo do tempo.
- Redes Neurais Artificiais
  > Modelos inspirados no funcionamento do cérebro humano que são usados p/ processar informações e tomar decisões.
- Processamento de Linguagem Natural (PLN)
  > O estudo da interação entre máquinas e linguagem humana, incluindo tarefas como tradução automática, reconhecimento de fala e análise de sentimento.
- Visão Computacional
  > Desenvolvimento de algoritmos e de sistemas capazes de entender e de interpretar imagens e vídeos.
- Robótica Inteligente
  > Combinação de IA e robótica p/ criar robôs capazes de interagir com o ambiente e realizar tarefas complexas.
- Sistemas Especialistas
  > Sistemas de IA projetados p/ imitar a inteligência e o conhecimento de especialistas humanos em um domínio específico.
- Algoritmos Genéticos
  > Técnicas de otimização baseadas em princípios genéticos e em evolução natural, usadas p/ resolver problemas complexos.
- Sistemas de Recomendação
  > Algoritmos que analisam dados e padrões de comportamento do usuário p/ fornecer sugestões personalizadas.
- IA Conversacional
  > Tecnologias que permitem a interação entre humanos e sistemas de IA por meio de diálogos naturais, como chatbots e assistentes virtuais.
- Mineração de Dados (Data Mining)
  > Técnicas p/ descobrir padrões e conhecimentos úteis a partir de conjuntos de dados grandes e complexos.
- Reconhecimento de Padrões
  > Identificação de padrões em dados, como reconhecimento facial, detecção de objetos e análise de imagem.
- IA Explicável
  > Desenvolvimento de métodos e de algoritmos que permitem entender e explicar o processo de tomada de decisão de sistemas de IA.
- Agentes Inteligentes
  > Programas de computador capazes de tomar decisões e agir de forma autônoma em um ambiente específico.
- Aprendizado Profundo (Deep Learning)
  > Subcampo do Machine Learning, utiliza Redes Neurais (unidades conectadas em rede p/ a análise de bancos de dados e informações) p/ emular o cérebro humano.
- Processamento de Sinais
  > Análise e interpretação de sinais (como áudio e vídeo) utilizando técnicas de IA.
- IA Responsável
  > Envolve garantir que a IA seja desevolvida e implementada de forma ética e legalmente responsável.
- Raciocínio Automatizado (Automated Reasoning)
  > Desenvolvimento de algoritmos e de técnicas p/ automatizar o processo de raciocínio lógico, permitindo que os computadores cheguem a conclusões ou provem teoremas de forma automatizada.

### 6.1.2 - Aprendizado de Máquina (AM)

- Def. — É a área da IA cujo objetivo é o _desenvolvimento de técnicas computacionais sobre o aprendizado_ bem como a construção de sistemas capazes de _adquirir conhecimento de forma automática_.

- [ _Vide figura do slide._ ]

### Hierarquia do conhecimento

1. Dado
2. Informação
3. Conhecimento
4. Sabedoria

### Definições de AM

- "Aprender implica em alterações no sistema que são adaptativas, no sentido que elas capacitam o sistema a realizar a mesma tarefa, ou tarefas provenientes da mesma população, de forma mais eficiente e eficaz na próxima vez." (Simon, 1983)

- "Um sistema de aprendizado [supervisionado] é um programa de computador que toma decisões baseadas na experiência contida em exemplos solucionados com sucesso." (Weiss & Kulikowski, 1991)

- "...todo aprendizado pode ser visto como o aprendizado de uma função" (Russel & Norvig, 1995)

### Tarefas de AM

- Tarefas **Descritivas**

  > Def. — Busca-se desenvolver algoritmos que _descreverão os dados_.

  > E.g: Agrupamento.

- Tarefas **Preditivas**

  > Def. — Busca-se desenvolver algoritmos p/ _realizar previsões de algo a partir de uma entrada de dados_.

  > Podem ser divididas em tarefas de _Classificação_ e de _Regressão_.

### Paradigmas de AM

- **Simbólico**

  > Def. — Construção de uma _representação simbólica de um conceito por meio de exemplos e contra-exemplos_.

  > Representação simbólica _na forma de alguma expressão lógica_, como árvores de decisão e regras.

- **Protótipo** ou **Memorização** (Instance Based)

  > Sistema que classifica um exemplo por meio de _exemplos similares conhecidos_.

  > Ex.: K-NN.

  - Sub-paradigmas:

    - Sistemas preguiçosos (lazy)
      > Necessitam manter os exemplos na memória p/ classificar novos exemplos.
    - Sistemas gulosos (eager)
      > Utilizam os exemplos p/ induzir o modelo, descartando-os logo após.

- **Conexionista**

  > Def. — Envolvem _unidades altamente interconectadas_.

  > Único ex. relevante: _Redes neurais_.

- **Genético**

  > Def. — Um classificador genético consiste de uma _população de elementos de classificação que competem p/ fazer a predição_.

  > Elementos que possuem um desempenho ruim são descartados, enquanto os elementos mais fortes proliferam, _produzindo variações_.

  > Alguns operadores genéticos básicos que aplicados a população geram novos indivíduos são: _Reprodução, Cruzamento, Mutação e Inversão_.

- **Estatístico**

  > Def. — Utilização de _modelos estatísticos p/ encontrar uma boa aproximação do conceito induzido_.

  > Vários desses métodos são _paramétricos_, assumindo alguma forma de modelo, e então encontrando valores apropriados p/ os parâmetros do modelo a partir dos exemplos.

  > Dentre os métodos estatísticos, destacam-se os de _aprendizado Bayesiano_, que utilizam um modelo probabilístico baseado no conhecimento prévio do problema, o qual é combinado com os exemplos de treinamento p/ determinar a probabilidade final de uma hipótese. Ex.: Naive Bayes.

### Árvore do Aprendizado Indutivo

- Aprendizado Indutivo

  - Aprendizado Supervisionado

    - Classificação

    - Regressão

  - Aprendizado Não Supervisionado

### Tipos de sistema de aprendizado

- **Não Simbólico** ou **Caixa-preta**

  - Não facilmente interpretado por humanos.

  - Desenvolve sua própria representação de conceitos.

  - Não fornece esclarecimento ou explicação sobre o processo de classificação.

- **Simbólico** ou **Orientado a Conhecimento**

  - Cria estruturas simbólicas que podem ser mais facilmente compreendidas por seres humanos.

  - "Os resultados da indução devem ser descrições simbólicas das entidades dadas... devem ser compreensíveis como simples 'pedados' de informação, diretamente interpretáveis em linguagem natural..." (Michalski 1983a)

### Outros conceitos importantes

- **Indutor**

  > Def. — Programa que gera uma hipótese (classificador) a partir de um conjunto de exemplos.

- **Exemplo, Caso ou Registro** (Instance)

  > Def. — É um conjunto fixo de atributos.

  > Um exemplo descreve o objeto de interesse, tal como um paciente, exemplos médicos sobre uma determinada doença, ou histórico de clientes de uma dada companhia.

- **Atributo ou Campo** (Feature)

  > Def. — Uma única característica de um exemplo.

- **Domínio**

  > Def. — Conjunto de valores que um atributo pode assumir.

- **Classe**

  > Def. — Atributo especial que descreve o fenômeno de interesse.

  > Aplicável somente no _Aprendizado Supervisionado_.

### Tipos de Atributo

- **Nominal** (ou Discreto ou Categórico)

  > Def. — O atributo assume valores em um conjunto finito.

  > Alguns indutores podem aceitar uma subdivisão entre os atributos nominais:

  - Ordenado
    > O domínio é ordenado, mas a diferença absoluta dos valores é desconhecida. E.g. escala de temperatura: baixa, média ou alta; severidade de um machucado.
  - Não-ordenado

    > Não existe uma ordem entre os valores. E.g. cor: vermelho, verde, azul; ocupação; estado civil; raça.

- **Contínuo** (ou Numérico ou Real)

  > Def. — O domínio do atributo é ordenado e pode ser representado por um valor real (e.g., peso ∈)

- **Desconhecido ou Faltante**

- **Não se aplica**

- **Relevante e Irrelevante**

  > Um atributo é irrelevante se existe uma descrição completa e consistente das classes a serem aprendidas que não usa aquele atributo.

> A busca é por atributos _com alto poder preditivo_.

### Conjunto de Treinamento e de Testes

- [ _Vide slides._ ]

### Classificador

- Def. — Dado um conjunto de treinamento, _um indutor gera como saída um classificador_ (hipótese ou descrição de conceito) de forma que, dado um novo exemplo, ele possa _predizer precisamente sua classe_.

- Cada exemplo é um par (x, f(x)), onde x é a entrada e f(x) é a saída (f desconhecida!).

- y = f(x) assume valores discretos y ∈ {C1, C2, ..., Ck} → _Classificação_.

- y = f(x) assume valores reais → _Regressão_.

- **Indução ou inferência indutiva**

  > Ex.: Dada uma coleção de exemplos de f(x), retornar uma função h(x) que aproxima f(x). Ou seja, h(x) ≅ f(x).

- **Bias** (viés)

  > Def. — Qualquer critério de preferência de uma hipótese sobre outra (além da consistência com os exemplos).

- **Indutor Instável vs. Estável**

  - Instável
    > Pequenas pertubação (variação) no conjunto de treinamento pode causar modificação no classificador gerado.
  - Estável
    > O classificador gerado não muda muito quando os exemplos de treinamento se alteram.

- **Trade-off entre Bias e Variância**

  - Indutores Instáveis
    > Em geral, geram classificadores com _alta variância_ mas com _pequeno bias_.
  - Indutores Estáveis
    > Em geral, geram classificadores com _baixa variância_ mas com _alto bias_.

- Indutor **Não Incremental** (modo batch) vs. Indutor **Incremental**

### Overfitting vs. Undertraining

> [ _Vide slide com gráfico._ ]

- Overfitting (overtraining)

  > Def. — A hipótese extraída a partir dos exemplos é muito específica p/ o conjunto de treinamento.

  - Para se **combater o overfitting**, pode-se:

    - > Diminuir a complexidade do modelo, e
    - > Usar métodos de validação cruzada.

- Underfitting

  > Def. — A hipótese induzida apresenta um desempenho ruim tanto no conjunto de treinamento como de teste.

  - Casos comuns:

    - > Poucos exemplos representativos foram dados ao sistema de aprendizado (e.g. algoritmos de árvore de decisão ou de indução de regras).

    - > O usuário pré-definiu um tamanho muito pequeno p/ o classificador (e.g. insuficientes neurônios em uma rede neural ou um alto valor de poda p/ árvores de decisão).

### Consistência e Completude de um classificador

- Completude

  > Tem a ver com o grau de preenchimento do espaço de exemplos do problema.

- Consistência

  > Tem a ver com a _taxa de acerto_ do classificador.

### Aprendizado Supervisionado vs. Não Supervisionado

- Aprendizado **Supervisionado**

  - Compreender o relacionamento entre os atributos e a classe.
  - Predizer a classe de novos exemplos o melhor possível.

- Aprendizado **Não Supervisionado**

  - Encontrar representações úteis dos exemplos, tais como:
    - Encontrar agrupamentos (clusters),
    - Redução da dimensão,
    - Encontrar as causas ou as fontes ocultas dos exemplos,
    - Modelar a densidade dos exemplos.

## 6.1.2 - Métricas de Classificação

### Matriz de Confusão

- > Def. — É uma tabela que permite a visualização do desempenho de um algoritmo de classificação.

- > [ Vide SLIDE p/ matriz. ]

```
                             Valor Previsto
                         Irregular | Ñ-Irregular
Valor      | Irregular       VP          FN
Verdadeiro | Ñ-Irregular     FP          VN
```

### Métricas

- **Positivos e Negativos:**

  - Verdadeiro Positivo (VP)
  - Verdadeiro Negativo (VN)
  - Falso Positivo (FP)
    > Erro do tipo I
  - Falso Negativo (FN)
    > Erro do tipo II

- **Acurácia e Erro:**

  > A Acurácia mede o percentual geral de acertos.

  - acurácia = (VP + VN) / total de amostras

  - erro = 1 - acurácia

- **Precisão:**

  > Indica, p/ as classificações _positivas_ do modelo, quantas foram acertadas.

  - precisão = VP / (VP + FP)

- **Recall, Revocação, Sensibilidade:**

  > Indica, p/ as amostras positivas existentes, quantas o modelo classificou corretamente.

  - recall = VP / (VP + FN)

- **Especificidade:**

  > Avalia a capacidade do método de detectar resultados negativos.

  - especificidade = VN / (VN + FP)

- F-Measure, F-Score ou Score F1:

  - f1 = 2 \* (precisão \* recall) / (precisão + recall)

### Resumo de Fórmulas

- **acurácia = (VP + VN) / total de amostras**
- erro = 1 - acurácia
- **precisão = VP / (VP + FP)**
- **recall = VP / (VP + FN)**
- especificidade = VN / (VN + FP)

### Navalha de Occam

- > Do latim "lex parsimoniae" — Lei da Parcimônia (conceito da economia).

- > Def. — A explicação de qualquer fenômeno deve fazer o _menor número possível de suposições_, eliminando aquelas que não fazem diferença nas predições observáveis da hipótese explicativa ou da teoria.

- **Dilema de Occam:**

  > Em AM, Acurácia e Simplicidade estão em conflito.

### Maldição da Dimensionalidade

- > Aprender a partir de um espaço de característica de _alta dimensionalidade_ requer uma _quantidade enorme de dados de treinamento_ p/ garantir que haja várias amostras com cada combinação de valores.

- > Def. — Com uma _quantidade fixa_ de número de instâncias de treinamento, _o poder de preditibilidade REDUZ à medida que aumenta a dimensionalidade_.

## 6.1.3 - Introdução à Classificação

- > Um problema de Classificação tem um _valor discreto_ como saída.

- > Def. — Classificação tem como finalidade atribuir um objeto/evento a uma categoria, pertencente a um conjunto finito de categorias.

### Aplicações

- Diagnóstico médico
- Detecção de fraude em cartões de crédito
- Detecção de vírus em redes de computadores
- Filtragem de spam em e-mails
- Bioinformática (sequências de DNA)
- Reconhecimento de caracteres
- Reconhecimento de imagens

### Exemplos de Classificador

- Árvores de Decisão
- Random Forest
- k-Nearest Neighbors (k-NN)
- Naive Bayes
- Regressão Logística
- Análise Discriminante Linear
- SVM (Support Vector Machine)
- \> **RNA (Redes Neurais Artificiais)** <

## 6.1.4 - Árvore de Decisão

- > Def. — É uma técnica utilizada p/ Classificação e _consiste em um mapa dos possíveis resultados de uma série de escolhas_ (White Model).

- > É formada por _3 partes principais_:

  - **Raiz**
    > É a primeira decisão a ser tomada pelo usuário.
  - **Nós**
    > São todas as decisões apresentadas na árvore.
  - **Folhas**
    > São os resultados da árvore de deciões. É nela que a Classificação é realizada.

  E.g. [ Vide SLIDES ]

- > Podem ser reescritas como um _conjunto de regras_, e.g. em Forma Normal Disjuntiva (DNF).

  - E.g. [ Vide SLIDE ]

- > Atributos contínuos podem ser usados, fazendo o nó dividir o domínio do atributo entre 2 intervalos baseados em um limite.

  - E.g. tamanho < 3 e tamanho >= 3.

- > Árvores de Classificação têm valores _discretos_ nas folhas. Árvores de Regressão têm valores _reais_ nas folhas.

- > Algoritmos p/ encontrar árvores consistentes são _eficientes_ e podem processar _grandes quantidades de dados de treinamento_.

- > _Não necessita de manipulação de dados_, como por ex. métodos de Normalização.

- > Alguns conceitos são de _difícil aprendizagem em Árvores de Decisão_, gerando Árvores extremamente grandes. E.g. XOR.

- > A maioria dos algoritmos de aprendizagem de Árvores _derivam do algoritmo ID3_:

  - > C4.5 e C5.0 são os mais recentes.
  - > O ID3 aprende a Árvore usando uma estratégia Top-Down.

### Algoritmo básico

- > O melhor atributo é selecionado e usado como Raiz da Árvore.

- > Um descendente (Sub-Árvore) do Nó raiz é então criado p/ cada valor possível deste atributo, e os exemplos de treinamento são ordenados p/ o Nó descendente apropriado.

- > O processo é repetido usando exemplos com cada Nó descendente p/ selecionar o melhor atributo p/ avaliar naquele ponto da Árvore.

### Overfitting

- [ Vide SLIDE p/ gráfico. ]

- P/ evitar Overfitting:

  - **Pré-Poda**

    > _Parar de crescer a Árvore_ quando não há mais dados suficientes p/ fazer previsões confiáveis.

  - **Pós-Poda**

    > _Construir a Árvore toda_, depois _remover Sub-Árvores com menos relevância_.

  - Métodos p/ Poda:

    - Validação Cruzada
      > Reservar alguns dados de treinamento (Conjunto de Validação) p/ avaliar utilidade das Sub-Árvores.
    - Testes Estatísticos
      > Usar o teste p/ determinar se a regularidade observada foi devida ao acaso.
    - Comprimento da Descrição Mínima (MDL)
      > Determinar se a complexidade adicional da hipótese é mais complexa que lembrar explicitamente as exceções resultantes da poda.

### Entropia de uma Árvore de Decisão

- > Def. — Aborda o aspecto da _quantidade de informações associadas às respostas que podem ser obtidas às perguntas formuladas_, representando o **Grau de Incerteza** associado aos dados.

- > Algoritmos de construção de Árvores de Decisão buscam _minimizar a informação necessária p/ classificar os dados nas partições da Árvore_.

## 6.1.5 - Algoritmos de Classificação

### Random Forest

- > Def. — É um algoritmo de Classificação baseado em Árvores de Decisão.

  E.g. [ Vide SLIDE ]

### k–Nearest Neighbors (k-NN)

- > Algoritmo **não paramétrico**.

- > Def. — É um algoritmo que _classifica novos dados com base em uma medida de similaridade entre seus **"vizinhos" mais próximos**_, ou seja, aqueles que têm características semelhantes às suas.

- > Nesse método, utiliza-se a _distância (usualmente a Euclidiana) entre uma nova observação e as demais observações de um Conjunto de Treinamento_ p/ classificá-la de acordo com a observação mais próxima.

- > O "k" determina o _número de vizinhos que serão utilizados p/ a classificação_.

  E.g. [ Vide SLIDES ]

- > O k-NN tbm é considerado um **Método de Imputação de Dados**.

### Naive Bayes

- > Def. — Família de algoritmos de Aprendizado Supervisionado baseados em probabilidade.

- **Teorema de Bayes:**

      P(A/B) = P(B/A) * P(A) / P(B)

  onde...

  - `P(A/B)` é a probde. de A ser Verd. dado que B é Verd..
  - `P(B/A)` é a probde. de B ser Verd. dado que A é Verd..
  - `P(A)` é a probde. de A ser Verd..
  - `P(B)` é a probde. de B ser Verd..

  E.g. [ Vide SLIDE ]

#### Características

- **Suposições ingênuas**

  - > Todas as características do Conjunto de Dados _não dependem umas das outras_.
  - > Sendo assim, cada evento _contribui igualmente_ p/ classificar o resultado.

- **Rápido**

  > Previsão em tempo real.

- Requer uma **quantidade reduzida de amostras**, se comparado a outros Algoritmos.

- Famoso como Classificador de **spam, sentimentos e recomendações**.

#### Funcionamento

1. > Prevê uma Tabela de Probabilidades Condicionais,

2. > E depois _calcula a saída com base nessa tabela_.
